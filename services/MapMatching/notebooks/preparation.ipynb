{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea61e564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "params = {'exec_id':0,'exclusions':[]}\n",
    "default = {'scenario': 'test', 'training_folder':'../..', 'params':params} # Default execution parameters\n",
    "manual, argv = (True, default) if 'ipykernel' in sys.argv[0] else (False, dict(default, **json.loads(sys.argv[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36b66424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add path to quetzal\n",
    "sys.path.insert(0,'../../../../quetzal/')\n",
    "from quetzal.model import stepmodel\n",
    "import os\n",
    "import numba as nb\n",
    "on_lambda = bool(os.environ.get('AWS_EXECUTION_ENV'))\n",
    "num_cores = nb.config.NUMBA_NUM_THREADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b016852",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = argv['scenario']\n",
    "training_folder = argv['training_folder']\n",
    "# if local. add the path to the scenario scenarios/<scenario>/\n",
    "if on_lambda:\n",
    "    input_folder = training_folder\n",
    "else:\n",
    "    input_folder = f'../scenarios/{scenario}/'\n",
    "parallel_folder = os.path.join(input_folder,'parallel')\n",
    "if not os.path.exists(parallel_folder):\n",
    "    os.makedirs(parallel_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4d5f4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exec_id': 0, 'exclusions': []}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argv['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb136465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09e7338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_id = argv['params'].get('exec_id',0)\n",
    "exclusions = argv['params'].get('exclusions',[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c45a578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12c7569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from quetzal.engine.add_network_mapmatching import duplicate_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca200ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = gpd.read_file(os.path.join(input_folder,'links.geojson'))\n",
    "links.set_index('index',inplace=True)\n",
    "nodes = gpd.read_file(os.path.join(input_folder,'nodes.geojson'))\n",
    "nodes.set_index('index',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ec64e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "links, nodes = duplicate_nodes(links,nodes)\n",
    "excluded_links = links[links['route_type'].isin(exclusions)]\n",
    "links = links[~links['route_type'].isin(exclusions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89eeb093",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_list = links['trip_id'].unique()\n",
    "num_trips = len(trip_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "641832b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_num_iteration = num_trips//num_cores\n",
    "def get_num_machine(num_it,target_it=20,choices=[12,8,4,2,1]):\n",
    "    # return the number of machine (in choices) requiresd to have target_it per machine).\n",
    "    num_machine = num_it /target_it\n",
    "    best_diff=100\n",
    "    best_val=12\n",
    "    for v in choices: # choice of output.\n",
    "        diff = abs(num_machine-v)\n",
    "        if diff < best_diff:\n",
    "            best_diff = diff\n",
    "            best_val=v\n",
    "    return best_val\n",
    "\n",
    "num_machine =  get_num_machine(tot_num_iteration, target_it=20, choices=[12,8,4,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cdaad557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num it per machine 26.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('num it per machine',tot_num_iteration/num_machine)\n",
    "\n",
    "chunk_length =  round(len(trip_list) / num_machine)\n",
    "# Split the list into four sub-lists\n",
    "chunks = [trip_list[j:j+chunk_length] for j in range(0, len(trip_list), chunk_length)]\n",
    "sum([len(c) for c in chunks]) == len(trip_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5cac28",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fcb121c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i,trips in enumerate(chunks):\n",
    "    print(i)\n",
    "    tlinks = links[links['trip_id'].isin(trips)]\n",
    "    nodes_set = set(tlinks['a'].unique()).union(set(tlinks['b'].unique()))\n",
    "    tnodes = nodes[nodes.reset_index()['index'].isin(nodes_set).values]\n",
    "    tlinks.to_file(os.path.join(input_folder, 'parallel', f'links_{i}.geojson'),driver='GeoJSON')\n",
    "    tnodes.to_file(os.path.join(input_folder, 'parallel', f'nodes_{i}.geojson'),driver='GeoJSON')\n",
    "\n",
    "if len(excluded_links)>0:\n",
    "    nodes_set = set(excluded_links['a'].unique()).union(set(excluded_links['b'].unique()))\n",
    "    tnodes = nodes[nodes.reset_index()['index'].isin(nodes_set).values]\n",
    "    excluded_links.to_file(os.path.join(input_folder, 'parallel', f'links_excluded.geojson'),driver='GeoJSON')\n",
    "    tnodes.to_file(os.path.join(input_folder, 'parallel', f'nodes_excluded.geojson'),driver='GeoJSON')\n",
    "#return num_machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d10fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_update(mapping, *updating_mappings):\n",
    "    # update a nested dict \n",
    "    # from Pydantic\n",
    "    # https://github.com/pydantic/pydantic/blob/fd2991fe6a73819b48c906e3c3274e8e47d0f761/pydantic/utils.py#L200\n",
    "    updated_mapping = mapping.copy()\n",
    "    for updating_mapping in updating_mappings:\n",
    "        for k, v in updating_mapping.items():\n",
    "            if k in updated_mapping and isinstance(updated_mapping[k], dict) and isinstance(v, dict):\n",
    "                updated_mapping[k] = deep_update(updated_mapping[k], v)\n",
    "            else:\n",
    "                updated_mapping[k] = v\n",
    "    return updated_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f00ae675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RETURN: {'launcher_arg': {'params': {'exec_id': [0, 1]}}}\n"
     ]
    }
   ],
   "source": [
    "# this is return to the main.py and in the step function event.\n",
    "ls = [i for i in range(num_machine)]\n",
    "d = {\"launcher_arg\":{\"params\":{\"exec_id\": ls}}}\n",
    "print(\"RETURN:\",d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quetzal_312",
   "language": "python",
   "name": "quetzal_312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
